{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather data from API\n",
    "ticker = yf.Ticker(\"MSFT\")\n",
    "data = ticker.history(\"max\")\n",
    "\n",
    "# Replacing spaces in column names with underscores\n",
    "data.columns = data.columns.str.replace(\" \", \"_\")\n",
    "\n",
    "# Define data folder path\n",
    "data_folder = Path.cwd() / 'data'\n",
    "\n",
    "# Define connection and cursor\n",
    "conn = sqlite3.connect(data_folder / 'market_data.db')\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_dataframe = pd.concat([data] * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table in SQLite\n",
    "create_sql = \"CREATE TABLE IF NOT EXISTS historical_prices \" \\\n",
    "\"(OPEN FLOAT, \" \\\n",
    "\"HIGH FLOAT, \" \\\n",
    "\"LOW FLOAT, \" \\\n",
    "\"CLOSE FLOAT, \" \\\n",
    "\"VOLUME INT, \" \\\n",
    "\"DIVIDENDS FLOAT, \" \\\n",
    "\"STOCK_SPLITS FLOAT)\"\n",
    "\n",
    "cursor.execute(create_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran this code block below twice and it inserted twice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in data.itertuples():\n",
    "#     insert_sql = f\"INSERT INTO historical_prices (OPEN, HIGH, LOW, CLOSE, VOLUME, DIVIDENDS, STOCK_SPLITS) VALUES ({row.Open}, {row.High}, {row.Low}, {row.Close}, {row.Volume}, {row.Dividends}, {row.Stock_Splits} )\"\n",
    "#     cursor.execute(insert_sql)\n",
    "    \n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This query below will replace the entire table with the dataframe\n",
    "    Questions:\n",
    "    - I wonder what would happen if the pandas dataframe was super large like a 3 million rows\n",
    "\n",
    "- For 9.8 million rows, the iteruples took 74.7 seconds to run\n",
    "- For 9.8 million rows, the df.to_sql took 12.3 seconds to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9830000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_dataframe.to_sql(\n",
    "    name = \"test_large_data\",\n",
    "    con=conn,\n",
    "    if_exists='replace',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if you insert into a table that doesn't exist?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
